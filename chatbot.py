import glob
import os
import json
import sys
import numpy as np
import faiss
import google.generativeai as genai
from sentence_transformers import SentenceTransformer

from dotenv import load_dotenv

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

sys.stdout.reconfigure(encoding='utf-8')

load_dotenv()

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

genai.configure(api_key=api_key)
model = genai.GenerativeModel("models/gemini-2.5-flash")

embedder = SentenceTransformer('intfloat/multilingual-e5-large-instruct')

BASE_DIR = "company_FAQ"

json_files = {
    "í…ŒìŠ¤íŠ¸": os.path.join(BASE_DIR, "converted_faq_*.json"),
    "íšŒì‚¬ì œë„": os.path.join(BASE_DIR, "company_policy.json"),
    "ì¸ì‚¬/ë³µì§€/ì¶œí‡´ê·¼": os.path.join(BASE_DIR, "hr_welfare_attendance.json"),
    "IT": os.path.join(BASE_DIR, "it.json"),
    "ì—…ë¬´íˆ´/í˜‘ì—…íˆ´": os.path.join(BASE_DIR, "collaboration_tools.json"),
    "ì¡°ì§/ë¶€ì„œ ì •ë³´": os.path.join(BASE_DIR, "organization_department.json"),
    "ì—…ë¬´ ì ˆì°¨/ê·œì •": os.path.join(BASE_DIR, "workflow_policy.json")
}

documents = []
doc_texts = []

for category, path_pattern in json_files.items():
    for path in glob.glob(path_pattern):
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                for entry in data:
                    documents.append((category, entry["question"], entry["answer"]))
                    doc_texts.append(entry["question"])

def embed_documents(texts):
    """ë¬¸ì„œ(FAQ ì§ˆë¬¸) ì„ë² ë”©"""
    prefixed = [
        f"Instruct: Retrieve semantically similar company FAQ questions\nQuery: {text}"
        for text in texts
    ]
    return embedder.encode(prefixed, convert_to_numpy=True, show_progress_bar=False)

def embed_query(query):
    """ì‚¬ìš©ì ì§ˆë¬¸ ì„ë² ë”©"""
    instruction = "Instruct: Given a user question, retrieve the most relevant company FAQ question\nQuery: "
    return embedder.encode([instruction + query], convert_to_numpy=True)

print("ì„ë² ë”© ìƒì„± ì¤‘...")
doc_embeddings = embed_documents(doc_texts)
dimension = doc_embeddings.shape[1]
index = faiss.IndexFlatIP(dimension)
faiss.normalize_L2(doc_embeddings)
index.add(doc_embeddings)
print(f"{len(documents)}ê°œ FAQ ë¡œë“œ ì™„ë£Œ!\n")

synonyms = {
    "ì›ê²©ê·¼ë¬´": "ì¬íƒê·¼ë¬´",
    "ì—°ì°¨": "íœ´ê°€",
    "VPN": "ì›ê²© ì ‘ì†",
    "ëŒ€í‘œë‹˜": "ëŒ€í‘œì´ì‚¬",
    "ì‚¬ì¥": "ëŒ€í‘œì´ì‚¬",
    "CEO": "ëŒ€í‘œì´ì‚¬",
}

def preprocess_question(q):
    """ì§ˆë¬¸ ì „ì²˜ë¦¬"""
    for key, val in synonyms.items():
        q = q.replace(key, val)
    return q.strip()

def keyword_match(question, documents):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì •í™• ë§¤ì¹­"""
    def normalize(text):
        return text.replace(" ", "").replace("?", "").replace("!", "").replace(".", "").lower()

    q_norm = normalize(question)

    for idx, (cat, q, a) in enumerate(documents):
        q_db_norm = normalize(q)

        if q_norm == q_db_norm or q_norm in q_db_norm or q_db_norm in q_norm:
            return idx, 1.0

        q_words = {w.strip("ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œì˜") for w in q.split() if len(w) >= 2}
        question_words = {w.strip("ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œì˜") for w in question.split() if len(w) >= 2}

        overlap = q_words & question_words

        if len(q_words) >= 2 and len(overlap) >= 2:
            if len(overlap) / len(q_words) >= 0.7:
                return idx, 0.95

    return None, 0.0

def ask_bot(question, debug=False):
    """FAQ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±"""

    question = preprocess_question(question)

    match_idx, match_score = keyword_match(question, documents)

    if match_idx is not None:
        category, matched_q, answer = documents[match_idx]
        if debug:
            print(f"í‚¤ì›Œë“œ ë§¤ì¹­ ì„±ê³µ ({match_score:.2f}): {matched_q}")
    else:
        q_vec = embed_query(question)
        faiss.normalize_L2(q_vec)

        similarities, indices = index.search(q_vec, 3)

        if debug:
            print("\në²¡í„° ê²€ìƒ‰ ê²°ê³¼:")
            for i in range(3):
                idx = indices[0][i]
                sim = similarities[0][i]
                cat, q, a = documents[idx]
                print(f"  {i+1}. [{sim:.4f}] {q}")

        best_sim = similarities[0][0]
        best_idx = indices[0][0]
        category, matched_q, answer = documents[best_idx]

        if debug:
            print(f"\nì„ íƒë¨: {matched_q}")

        if best_sim < 0.4:
            if debug:
                print(f"ìœ ì‚¬ë„ ë‚®ìŒ ({best_sim:.4f}) - FAQì— ì—†ëŠ” ì§ˆë¬¸ì¼ ìˆ˜ ìˆìŒ")

    prompt = f"""ë‹¹ì‹ ì€ íšŒì‚¬ FAQ ì±—ë´‡ì…ë‹ˆë‹¤.

[ê²€ìƒ‰ëœ FAQ]
ì¹´í…Œê³ ë¦¬: {category}
ì§ˆë¬¸: {matched_q}
ë‹µë³€: {answer}

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

**ì¤‘ìš” ì§€ì¹¨:**
1. ìœ„ FAQê°€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **íšŒì‚¬ ì—…ë¬´/ì •ì±…/ì œë„/ìœ„í‚¤ì™€ ì§ì ‘ ê´€ë ¨**ì´ ìˆë‹¤ë©´ FAQ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. í•˜ì§€ë§Œ FAQì™€ ì‚¬ìš©ì ì§ˆë¬¸ì´ **ë‹¨ìˆœíˆ ì£¼ì œë§Œ ë¹„ìŠ·**í•˜ê±°ë‚˜, **íšŒì‚¬ì™€ ë¬´ê´€í•œ ì¼ë°˜ ìƒì‹ ì§ˆë¬¸**ì´ë¼ë©´:
   - "ğŸ’¡ í•´ë‹¹ ì§ˆë¬¸ì€ íšŒì‚¬ FAQì— í¬í•¨ë˜ì§€ ì•Šì€ ë‚´ìš©ì…ë‹ˆë‹¤." ë¼ê³  ë¨¼ì € ë§í•˜ê³ 
   - ê·¸ ë‹¤ìŒ ì¤„ì— ì¼ë°˜ ìƒì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
"""

    response = model.generate_content(prompt)
    return response.text.strip()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class QuestionRequest(BaseModel):
    question: str

class FaqAnswer(BaseModel):
    answer: str

@app.post("/api/faq/ask", response_model=FaqAnswer)
def api_ask(req: QuestionRequest):
    """í”„ë¡ íŠ¸/ë°±ì—”ë“œì—ì„œ í˜¸ì¶œí•  HTTP ì—”ë“œí¬ì¸íŠ¸"""
    answer_text = ask_bot(req.question, debug=False)
    return FaqAnswer(answer=answer_text)

# 4. ì½˜ì†”ì—ì„œ ëŒë¦¬ê³  ì‹¶ì„ ë•Œ (ì˜µì…˜)
def chat_mode():
    print("\n" + "="*70)
    print("FAQ ì±—ë´‡ (ì¢…ë£Œ: 'exit' ë˜ëŠ” 'ì¢…ë£Œ')")
    print("="*70 + "\n")

    while True:
        question = input("ì§ˆë¬¸: ").strip()

        if question.lower() in ['exit', 'ì¢…ë£Œ', 'quit']:
            print("\n ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not question:
            continue

        answer = ask_bot(question, debug=True)
        print(f"\në‹µë³€:\n{answer}\n")
        print("-"*70 + "\n")

if __name__ == "__main__":
    chat_mode()