import os
import re
import json
import time
import pymysql
import google.generativeai as genai
from dotenv import load_dotenv
from pathlib import Path

# --------------------------------------------------
# 0) ê¸°ë³¸ ì„¤ì • (ê²½ë¡œ / í™˜ê²½ë³€ìˆ˜ / Gemini ì„¤ì •)
# --------------------------------------------------

# ì´ íŒŒì¼(convert.py)ì´ ìˆëŠ” í´ë” ê¸°ì¤€
BASE_DIR = Path(__file__).resolve().parent

# .env ë¡œë“œ
load_dotenv(BASE_DIR / ".env")

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    raise RuntimeError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

GENAI_MODEL_NAME = "models/gemini-2.5-flash"
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel(GENAI_MODEL_NAME)

# --------------------------------------------------
# 1) DB ì„¤ì • (.envì—ì„œ ì½ê¸°)
# --------------------------------------------------

DB_HOST = os.environ["DB_HOST"]
DB_PORT = int(os.environ["DB_PORT"])
DB_USER = os.environ["DB_USER"]
DB_PASSWORD = os.environ["DB_PASSWORD"]
DB_NAME = os.environ["DB_NAME"]

# ìœ„í‚¤ê°€ ì €ì¥ëœ í…Œì´ë¸”/ì»¬ëŸ¼ëª… (í”„ë¡œì íŠ¸ DB êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •)
WIKI_TABLE = "wiki"
WIKI_TITLE_COL = "title"
WIKI_CONTENT_COL = "content"
WIKI_IS_DELETED_COL = "isdeleted"  # ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ì‚¬ìš©

# JSON ì¶œë ¥ ê²½ë¡œ: convert.pyê°€ ìˆëŠ” í´ë” ê¸°ì¤€ company_FAQ í´ë”
OUTPUT_DIR = BASE_DIR / "company_FAQ"
BASE_FILE_NAME = "converted_faq"  # converted_faq_1.json, converted_faq_2.json ...
MAX_ITEMS_PER_FILE = 500          # í•œ íŒŒì¼ë‹¹ ìµœëŒ€ FAQ ê°œìˆ˜


# --------------------------------------------------
# 2) DBì—ì„œ ìœ„í‚¤ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
# --------------------------------------------------

def fetch_wiki_from_db() -> str:
    """
    DBì—ì„œ ìœ„í‚¤ë“¤ì„ ì½ì–´ì™€ì„œ,
    ê° rowë¥¼ "ì œëª©: ë‚´ìš©" í˜•ì‹ì˜ ë¸”ë¡ìœ¼ë¡œ ë§Œë“¤ì–´ \n\n ë¡œ ì´ì–´ë¶™ì¸ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    """
    conn = pymysql.connect(
        host=DB_HOST,
        port=DB_PORT,
        user=DB_USER,
        password=DB_PASSWORD,
        db=DB_NAME,
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )

    try:
        with conn.cursor() as cur:
            sql = f"""
            SELECT {WIKI_TITLE_COL}   AS title,
                   {WIKI_CONTENT_COL} AS content
            FROM {WIKI_TABLE}
            WHERE {WIKI_IS_DELETED_COL} = 0
            """
            cur.execute(sql)
            rows = cur.fetchall()
    finally:
        conn.close()

    blocks = []
    for row in rows:
        title = row["title"] or ""
        content = row["content"] or ""
        blocks.append(f"{title}: {content}")

    text = "\n\n".join(blocks)
    print(f"DBì—ì„œ {len(rows)}ê°œ ìœ„í‚¤ë¥¼ ì½ì–´ì™”ìŠµë‹ˆë‹¤.")
    return text


# --------------------------------------------------
# 3) í…ìŠ¤íŠ¸ë¥¼ ì ë‹¹í•œ ê¸¸ì´ì˜ chunkë¡œ ë‚˜ëˆ„ê¸°
# --------------------------------------------------

def split_to_chunks(text: str):
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨/ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ chunk ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    """
    # 1) ë¬¸ë‹¨ ê¸°ì¤€ ë¶„ë¦¬
    paragraphs = re.split(r'\n\s*\n', text.strip())
    paragraphs = [p.strip() for p in paragraphs if p.strip()]

    chunks = []

    for para in paragraphs:
        # ë„ˆë¬´ ê¸¸ë©´ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¬ë¶„í• 
        if len(para) > 300:
            sentences = re.split(r'(?<=\.)\s+', para)
            buffer = ""

            for sent in sentences:
                if len(buffer) + len(sent) < 250:
                    buffer += sent + " "
                else:
                    chunks.append(buffer.strip())
                    buffer = sent + " "

            if buffer.strip():
                chunks.append(buffer.strip())
        else:
            chunks.append(para)

    print(f"ì´ {len(chunks)}ê°œì˜ chunkë¡œ ë¶„ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return chunks


# --------------------------------------------------
# 4) Geminië¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ ìƒì„±
# --------------------------------------------------

def generate_question_with_gemini(chunk: str) -> str:
    """
    chunk ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ì‹¤ì œ ì‚¬ëŒì´ ë¬¼ì–´ë³¼ ë§Œí•œ FAQ ì§ˆë¬¸ í•œ ë¬¸ì¥ì„ Geminiì—ê²Œ ìƒì„± ìš”ì²­.
    """
    prompt = f"""
ì•„ë˜ ë‚´ìš©ì„ ì½ê³ , ì‹¤ì œ ì‚¬ìš©ìê°€ ì´ ë‚´ìš©ì„ ì§ˆë¬¸í•˜ë ¤ê³  í•  ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³¼ 'FAQ ìŠ¤íƒ€ì¼ ì§ˆë¬¸'ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.

ë‚´ìš©:
\"\"\"{chunk}\"\"\"


ì§ˆë¬¸ ìƒì„± ê·œì¹™:
- ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì¼ ê²ƒ
- "ì´ ë¬¸ë‹¨", "ë‚´ìš©", "í•µì‹¬" ê°™ì€ ë‹¨ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ê°€ê²Œ, ì œë„, ì„¤ëª… ë“±ì˜ ëŒ€ìƒì— ë§ì¶° ì‹¤ì œ ì‚¬ëŒì´ ë¬»ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ì„±
- ì˜ˆì‹œì™€ ìœ ì‚¬í•œ í†¤ì„ ì‚¬ìš©í•  ê²ƒ:
  - íšŒì‚¬ ê·¼ì²˜ì— ì–´ë–¤ ë§›ì§‘ì´ ìˆë‚˜ìš”?
  - ê¹€ë°¥ì²œêµ­ì€ ì–´ë–¤ ê³³ì¸ê°€ìš”?
  - ì´ ê°€ê²Œì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?
  - ì–´ë–¤ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë‚˜ìš”?
- ë‹µë³€ì— ì§ì ‘ ë“±ì¥í•˜ëŠ” ëŒ€ìƒ(ê°€ê²Œëª…, ê°œë…ëª…)ì„ ì‚¬ìš©í•´ ì§ˆë¬¸ì„ êµ¬ì„±í•  ê²ƒ

ì¶œë ¥ í˜•ì‹:
- ì§ˆë¬¸ ë¬¸ì¥ë§Œ ì¶œë ¥
"""

    response = model.generate_content(prompt)
    question = (response.text or "").strip()
    question = question.replace("ì§ˆë¬¸:", "").strip()

    # ë„ˆë¬´ ê¸¸ë©´ ì¡°ê¸ˆ ì˜ë¼ì£¼ê¸°
    if len(question) > 120:
        question = question[:120] + "..."

    return question


# --------------------------------------------------
# 5) chunks â†’ (Q, A) entry ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°
# --------------------------------------------------

def build_entries_from_text(text: str):
    """
    ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ chunkë¥¼ ë§Œë“¤ê³ ,
    ê° chunkì— ëŒ€í•´ (question, answer) entryë¥¼ ìƒì„±í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    """
    chunks = split_to_chunks(text)
    entries = []

    for idx, chunk in enumerate(chunks, start=1):
        print(f"\nâ–¶ [{idx}/{len(chunks)}] Gemini ì§ˆë¬¸ ìƒì„± ì¤‘â€¦")

        # ë¬´ë£Œ í‹°ì–´: ë¶„ë‹¹ 10íšŒ ì œí•œ â†’ í˜¸ì¶œ ê°„ê²©ì„ ë„‰ë„‰í•˜ê²Œ ë²Œë ¤ì¤Œ
        if idx > 1:
            time.sleep(7)  # ë‘ ë²ˆì§¸ í˜¸ì¶œë¶€í„° 7ì´ˆ ì‰¬ê³  í˜¸ì¶œ

        q = generate_question_with_gemini(chunk)

        entries.append({
            "question": q,
            "answer": chunk,  # ì¼ë‹¨ì€ chunk ì „ì²´ë¥¼ answerë¡œ ì‚¬ìš©
        })

    print(f"\nì´ {len(entries)}ê°œì˜ FAQ ì—”íŠ¸ë¦¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return entries


# --------------------------------------------------
# 6) JSON ì €ì¥ (ì—¬ëŸ¬ íŒŒì¼ë¡œ ë‚˜ëˆ„ê¸°)
# --------------------------------------------------

def save_as_multi_json(entries):
    """
    entries ë¦¬ìŠ¤íŠ¸ë¥¼ MAX_ITEMS_PER_FILE ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼
    converted_faq_1.json, converted_faq_2.json ... í˜•íƒœë¡œ ì €ì¥.
    """
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    total = len(entries)
    if total == 0:
        print("ì €ì¥í•  entryê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    file_index = 1
    for i in range(0, total, MAX_ITEMS_PER_FILE):
        slice_entries = entries[i: i + MAX_ITEMS_PER_FILE]
        file_path = OUTPUT_DIR / f"{BASE_FILE_NAME}_{file_index}.json"

        with file_path.open("w", encoding="utf-8") as f:
            json.dump(slice_entries, f, indent=2, ensure_ascii=False)

        print(f" {len(slice_entries)}ê°œë¥¼ {file_path} ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        file_index += 1

    print(f"\nJSON íŒŒì¼ ì €ì¥ ì™„ë£Œ! (ì´ {file_index - 1}ê°œ íŒŒì¼)")

    # ğŸ” ë””ë²„ê¹…ìš©: ì‹¤ì œë¡œ ì–´ë–¤ ê²½ë¡œ/íŒŒì¼ì„ ë³´ê³  ìˆëŠ”ì§€ ì¶œë ¥
    print("\n[DEBUG] í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:", os.getcwd())
    print("[DEBUG] OUTPUT_DIR:", OUTPUT_DIR)
    try:
        print("[DEBUG] OUTPUT_DIR ì•ˆì˜ íŒŒì¼ë“¤:", [p.name for p in OUTPUT_DIR.iterdir()])
    except FileNotFoundError:
        print("[DEBUG] OUTPUT_DIR ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


# --------------------------------------------------
# 7) ë©”ì¸ ì‹¤í–‰
# --------------------------------------------------

def export_from_db_to_multi_json():
    # 1) DBì—ì„œ ìœ„í‚¤ ì½ì–´ì˜¤ê¸°
    text = fetch_wiki_from_db()

    if not text.strip():
        print("DBì—ì„œ ê°€ì ¸ì˜¨ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 2) (Q, A) ì—”íŠ¸ë¦¬ ìƒì„±
    entries = build_entries_from_text(text)

    # 3) ì—¬ëŸ¬ JSON íŒŒì¼ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥
    save_as_multi_json(entries)


if __name__ == "__main__":
    export_from_db_to_multi_json()
